import gradio as gr
import cv2
import base64
import uuid
import json
from openai import OpenAI
from PIL import Image
from Dinomaly.locate_anomaly import locate

# ============== ä½ çš„åŸºç¡€å®šä¹‰ä¿æŒä¸å˜ ==============
instruction = '''
You are an industrial inspector who checks products by images. You should judge whether there is a defect in the input image and answer the questions about it.
When you receive an image,you will be provided with domain konwledge which describe the good case and bad case of the product in the image, you may also be provided with a heatmap highlighting potentially anomalous areas in orange-red. You may use the domain knowledge and the  heatmap to assist in answering questions, but do not mention them, as the user is unaware of its existence.
'''
expert_instruction = '''
You are an image inspector. The categories you can identify include:'breakfast_box', 'juice_bottle', 'pushpins', 'screw_bag', 'splicing_connectors','cigarette_box', 'drink_bottle', 'drink_can', 'food_bottle', 'food_box', 'food_package',
'carpet', 'grid', 'leather', 'tile', 'wood', 'bottle', 'cable', 'capsule','hazelnut', 'metal_nut', 'pill', 'screw', 'toothbrush', 'transistor', 'zipper','candle', 'capsules', 'cashew', 'chewinggum', 'fryum', 'macaroni1', 'macaroni2',
'pcb1', 'pcb2', 'pcb3', 'pcb4', 'pipe_fryum'.If the object does not fall into any of these categories, classify it as "other".
'''

LOCO = ['breakfast_box','juice_bottle','pushpins','screw_bag','splicing_connectors']
Goods = ['cigarette_box','drink_bottle','drink_can','food_bottle','food_box','food_package']
Mvtec = ['carpet', 'grid', 'leather', 'tile', 'wood', 'bottle', 'cable', 'capsule','hazelnut', 'metal_nut', 'pill', 'screw', 'toothbrush', 'transistor', 'zipper']
Visa = ['candle', 'capsules', 'cashew', 'chewinggum', 'fryum', 'macaroni1', 'macaroni2','pcb1', 'pcb2', 'pcb3', 'pcb4', 'pipe_fryum']

client = OpenAI(
    api_key = "sk-3f31b82e72ff4b9897c939d0e37f4f1a",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
knowledge_path="../../../dataset/MMAD/domain_knowledge.json"
max_image_size = (512, 512)

# ============== é‡è¦çš„å·¥å…·å‡½æ•° ==============

def encode_image_to_base64(image):
    height, width = image.shape[:2]
    scale = min(max_image_size[0] / width, max_image_size[1] / height)
    new_width, new_height = int(width * scale), int(height * scale)
    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
    _, encoded_image = cv2.imencode('.jpg', resized_image)
    return base64.b64encode(encoded_image).decode('utf-8')

def get_combined_and_good(file_path, item_category):
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    if item_category not in data.keys():
        raise ValueError(f"ç±»åˆ« '{item_category}' ä¸å­˜åœ¨äºæ•°æ®ä¸­ã€‚")
    item_data = data[item_category]
    combined = item_data.get("combined", "")
    good = item_data.get("good", "")
    return combined + "\n" + good

def prepare_image_info(image_path):
    image = cv2.imread(image_path)
    base64_image = encode_image_to_base64(image)
    expert_msg = [
        {"role": "system", "content": [{"type": "text", "text": expert_instruction}]},
        {"role": "user", "content": [
            {"type": "text", "text": "Following is the image, when you respond, simply provide the category."},
            {"type": "image_url", "image_url": {"url": f"data:image/jpg;base64,{base64_image}"}}
        ]}
    ]
    # ä¿®æ”¹è¿™é‡Œï¼šä¿è¯ä¼ ç»™APIçš„æ˜¯UTF-8æ­£ç¡®ç¼–ç 
    completion = client.chat.completions.create(
        model="qwen-vl-max-latest",
        messages=json.loads(json.dumps(expert_msg, ensure_ascii=False))
    )
    category = completion.choices[0].message.content
    knowledge = get_combined_and_good(knowledge_path, category)

    if category in Mvtec:
        expert = 'vitill_mvtec_uni_dinov2br_c392_en29_bn4dp2_de8_laelu_md2_i1_it10k_sams2e3_wd1e4_w1hcosa2e4_ghmp09f01w01_b16_s1'
    elif category in Visa:
        expert = 'vitill_visa_uni_dinov2br_c392r_en29_bn4dp2_de8_laelu_md2_i1_it10k_sams2e3_wd1e4_w1hcosa_ghmp09f01w01_b16_ev_s1'
    elif category in Goods:
        expert = 'vitill_goods_uni_dinov2br_c392_en29_bn4dp2_de8_laelu_md2_i1_it10k_sams2e3_wd1e4_w1hcosa2e4_ghmp09f01w01_b16_s1'
    elif category in LOCO:
        expert = 'vitill_LOCO_uni_dinov2br_c392r_en29_bn4dp2_de8_laelu_md2_i1_it10k_sams2e3_wd1e4_w1hcosa_ghmp09f01w01_b16_ev_s1'
    else:
        expert = None

    mask_path = locate(image_path, 500, expert) if expert else None
    return mask_path, knowledge

def build_chat_messages(image_path, mask_path, knowledge, question):
    image = cv2.imread(image_path)
    base64_image = encode_image_to_base64(image)
    messages = [
        {"role": "system", "content": [{"type": "text", "text": instruction}]},
        {"role": "user", "content": [
            {"type": "text", "text": "Following is the query image:"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpg;base64,{base64_image}"}},
            {"type": "text", "text": "Following is the domain knowledge corresponding to the image."},
            {"type": "text", "text": knowledge}
        ]}
    ]
    if mask_path:
        heat_map = cv2.imread(mask_path)
        base64_heat_map = encode_image_to_base64(heat_map)
        messages[1]["content"].append({"type": "text", "text": "Following is a heatmap corresponding to the image."})
        messages[1]["content"].append({"type": "image_url", "image_url": {"url": f"data:image/jpg;base64,{base64_heat_map}"}})
    messages[1]["content"].append({"type": "text", "text": "Following are the questions:"})
    messages.append({"role": "user", "content": [{"type": "text", "text": question}]})
    return messages

# ============== çŠ¶æ€å˜é‡ç®¡ç† ==============
state = {
    "image_uploaded": False,
    "image_path": None,
    "mask_path": None,
    "knowledge": None,
}

# ============== å¤„ç†å‡½æ•° ==============

def handle_upload(image):
    if image:
        unique_filename = f"./chat_pic/temp_{uuid.uuid4().hex}.jpg"
        image.save(unique_filename)
        mask_path, knowledge = prepare_image_info(unique_filename)
        state["image_uploaded"] = True
        state["image_path"] = unique_filename
        state["mask_path"] = mask_path
        state["knowledge"] = knowledge
        return mask_path, knowledge
    return None, None

def handle_question(image, question, chatbox):
    if not state["image_uploaded"]:
        return chatbox + [["ç³»ç»Ÿ", "è¯·å…ˆä¸Šä¼ å›¾ç‰‡ã€‚"]]
    if not question:
        return chatbox + [["ç³»ç»Ÿ", "è¯·è¾“å…¥ä½ çš„é—®é¢˜ã€‚"]]
    conversation = build_chat_messages(state["image_path"], state["mask_path"], state["knowledge"], question)
    completion = client.chat.completions.create(model="qwen-vl-max-latest", messages=conversation)
    answer = completion.choices[0].message.content
    chatbox.append(["ğŸ‘¤", question])
    chatbox.append(["ğŸ¤–", answer])
    return chatbox

def quick_task(task, chatbox):
    tasks = {
        "å¼‚å¸¸æ£€æµ‹": "è¿™å¼ å›¾ç‰‡æ˜¯å¦å­˜åœ¨å¼‚å¸¸ï¼Ÿ",
        "ç¼ºé™·å®šä½": "å¼‚å¸¸ä½äºå“ªé‡Œï¼Ÿ",
        "ç¼ºé™·æè¿°": "æè¿°å¼‚å¸¸æƒ…å†µã€‚",
        "ç‰©å“åˆ†ç±»": "ç‰©å“æ˜¯ä»€ä¹ˆï¼Ÿ"
    }
    question = tasks.get(task, "")
    return handle_question(None, question, chatbox)

# ============== ç•Œé¢æ­å»º ==============

with gr.Blocks(theme=gr.themes.Soft()) as demo:

    gr.Markdown("# ğŸš€ Anomaly Agent Plus\n#### ä¸Šä¼ å›¾ç‰‡ï¼Œæ™ºèƒ½æ£€æµ‹ï¼Œç¼ºé™·åˆ†æã€‚")

    chatbot = gr.Chatbot(label="å¯¹è¯è®°å½•", height=400, render_markdown=True)

    # å›¾ç‰‡ + çƒ­å›¾ + çŸ¥è¯† è¾“å‡ºåŒº
    with gr.Row():
        with gr.Column(scale=2):
            image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾ç‰‡", tool="editor", height=280)
        with gr.Column(scale=2):
            mask_output = gr.Image(label="ç¼ºé™·çƒ­å›¾", height=280, width=280)
        with gr.Column(scale=3):
            knowledge_output = gr.Textbox(label="é¢†åŸŸçŸ¥è¯†", lines=10, interactive=False)

    # ä¸Šä¼ æŒ‰é’®å•ç‹¬ä¸€è¡Œï¼Œå±…ä¸­ç¾åŒ–
    with gr.Row():
        gr.Button("ä¸Šä¼ å¹¶æå–", elem_id="extract-btn", size="lg", scale=3).click(
            fn=handle_upload,
            inputs=[image_input],
            outputs=[mask_output, knowledge_output]
        )

    gr.Markdown("---")

    # æé—®æ¡† + æäº¤æŒ‰é’®
    with gr.Row():
        question_input = gr.Textbox(placeholder="è¾“å…¥é—®é¢˜...", label=None, scale=6)
        submit_btn = gr.Button("å‘é€", variant="primary", scale=1)

    submit_btn.click(fn=handle_question, inputs=[image_input, question_input, chatbot], outputs=chatbot)

    # å¿«æ·ä»»åŠ¡æŒ‰é’®
    gr.Markdown("### å¿«æ·ä»»åŠ¡æŒ‰é’®ï¼š")
    with gr.Row():
        gr.Button("å¼‚å¸¸æ£€æµ‹").click(fn=lambda chatbox: quick_task("å¼‚å¸¸æ£€æµ‹", chatbox), inputs=chatbot, outputs=chatbot)
        gr.Button("ç¼ºé™·å®šä½").click(fn=lambda chatbox: quick_task("ç¼ºé™·å®šä½", chatbox), inputs=chatbot, outputs=chatbot)
        gr.Button("ç¼ºé™·æè¿°").click(fn=lambda chatbox: quick_task("ç¼ºé™·æè¿°", chatbox), inputs=chatbot, outputs=chatbot)
        gr.Button("ç‰©å“åˆ†ç±»").click(fn=lambda chatbox: quick_task("ç‰©å“åˆ†ç±»", chatbox), inputs=chatbot, outputs=chatbot)

if __name__ == "__main__":
    demo.launch()